{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install kaggle-environments -U > /dev/null 2>&1\n!cp -r ../input/lux-ai-2021/* .","metadata":{"execution":{"iopub.status.busy":"2021-10-21T10:59:25.278333Z","iopub.execute_input":"2021-10-21T10:59:25.278680Z","iopub.status.idle":"2021-10-21T10:59:34.172783Z","shell.execute_reply.started":"2021-10-21T10:59:25.278595Z","shell.execute_reply":"2021-10-21T10:59:34.171853Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport json\nfrom pathlib import Path\nimport os\nimport random\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\nimport math\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-21T10:59:34.174782Z","iopub.execute_input":"2021-10-21T10:59:34.175036Z","iopub.status.idle":"2021-10-21T10:59:39.440723Z","shell.execute_reply.started":"2021-10-21T10:59:34.175006Z","shell.execute_reply":"2021-10-21T10:59:39.439985Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed_value):\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    os.environ['PYTHONHASHSEED'] = str(seed_value)\n    \n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = True\n\nseed = 42\nseed_everything(seed)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T10:59:39.442027Z","iopub.execute_input":"2021-10-21T10:59:39.442276Z","iopub.status.idle":"2021-10-21T10:59:39.491327Z","shell.execute_reply.started":"2021-10-21T10:59:39.442244Z","shell.execute_reply":"2021-10-21T10:59:39.490656Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"def to_label(action):\n    strs = action.split(' ')\n    unit_id = strs[1]\n    if strs[0] == 'm':\n        label = {'c': None, 'n': 0, 's': 1, 'w': 2, 'e': 3}[strs[2]]\n    elif strs[0] == 'bcity':\n        label = 4\n    else:\n        label = None\n    return unit_id, label\n\n\ndef depleted_resources(obs):\n    for u in obs['updates']:\n        if u.split(' ')[0] == 'r':\n            return False\n    return True\n\n\ndef create_dataset_from_json(episode_dir, team_name='Toad Brigade'): \n    obses = {}\n    samples = []\n    append = samples.append\n    \n    episodes = [path for path in Path(episode_dir).glob('*.json') if 'output' not in path.name]\n    for filepath in tqdm(episodes): \n        with open(filepath) as f:\n            json_load = json.load(f)\n\n        ep_id = json_load['info']['EpisodeId']\n        index = np.argmax([r or 0 for r in json_load['rewards']])\n        if json_load['info']['TeamNames'][index] != team_name:\n            continue\n\n        for i in range(len(json_load['steps'])-1):\n            if json_load['steps'][i][index]['status'] == 'ACTIVE':\n                actions = json_load['steps'][i+1][index]['action']\n                obs = json_load['steps'][i][0]['observation']\n                \n                if depleted_resources(obs):\n                    break\n                \n                obs['player'] = index\n                obs = dict([\n                    (k,v) for k,v in obs.items() \n                    if k in ['step', 'updates', 'player', 'width', 'height']\n                ])\n                obs_id = f'{ep_id}_{i}'\n                obses[obs_id] = obs\n                                \n                for action in actions:\n                    unit_id, label = to_label(action)\n                    if label is not None:\n                        append((obs_id, unit_id, label))\n\n    return obses, samples","metadata":{"execution":{"iopub.status.busy":"2021-10-21T10:59:39.493304Z","iopub.execute_input":"2021-10-21T10:59:39.493561Z","iopub.status.idle":"2021-10-21T10:59:39.507618Z","shell.execute_reply.started":"2021-10-21T10:59:39.493528Z","shell.execute_reply":"2021-10-21T10:59:39.506877Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"episode_dir = '../input/lux-ai-episodes'\nobses, samples = create_dataset_from_json(episode_dir)\nprint('obses:', len(obses), 'samples:', len(samples))","metadata":{"execution":{"iopub.status.busy":"2021-10-21T10:59:39.509847Z","iopub.execute_input":"2021-10-21T10:59:39.511835Z","iopub.status.idle":"2021-10-21T10:59:43.775494Z","shell.execute_reply.started":"2021-10-21T10:59:39.511799Z","shell.execute_reply":"2021-10-21T10:59:43.774722Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nlabels = [sample[-1] for sample in samples]\nactions = ['north', 'south', 'west', 'east', 'bcity']\nn_actions = 5\nfor value, count in zip(*np.unique(labels, return_counts=True)):\n    print(f'{actions[value]:^5}: {count:>3}')","metadata":{"execution":{"iopub.status.busy":"2021-10-21T11:22:04.728028Z","iopub.execute_input":"2021-10-21T11:22:04.728779Z","iopub.status.idle":"2021-10-21T11:22:04.773092Z","shell.execute_reply.started":"2021-10-21T11:22:04.728721Z","shell.execute_reply":"2021-10-21T11:22:04.771918Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# Input for Neural Network\ndef make_input(obs, unit_id):\n    width, height = obs['width'], obs['height']\n    x_shift = (32 - width) // 2\n    y_shift = (32 - height) // 2\n    cities = {}\n    \n    b = np.zeros((20, 32, 32), dtype=np.float32)\n    \n    for update in obs['updates']:\n        strs = update.split(' ')\n        input_identifier = strs[0]\n        \n        if input_identifier == 'u':\n            x = int(strs[4]) + x_shift\n            y = int(strs[5]) + y_shift\n            wood = int(strs[7])\n            coal = int(strs[8])\n            uranium = int(strs[9])\n            if unit_id == strs[3]:\n                # Position and Cargo\n                b[:2, x, y] = (\n                    1,\n                    (wood + coal + uranium) / 100\n                )\n            else:\n                # Units\n                team = int(strs[2])\n                cooldown = float(strs[6])\n                idx = 2 + (team - obs['player']) % 2 * 3\n                b[idx:idx + 3, x, y] = (\n                    1,\n                    cooldown / 6,\n                    (wood + coal + uranium) / 100\n                )\n        elif input_identifier == 'ct':\n            # CityTiles\n            team = int(strs[1])\n            city_id = strs[2]\n            x = int(strs[3]) + x_shift\n            y = int(strs[4]) + y_shift\n            idx = 8 + (team - obs['player']) % 2 * 2\n            b[idx:idx + 2, x, y] = (\n                1,\n                cities[city_id]\n            )\n        elif input_identifier == 'r':\n            # Resources\n            r_type = strs[1]\n            x = int(strs[2]) + x_shift\n            y = int(strs[3]) + y_shift\n            amt = int(float(strs[4]))\n            b[{'wood': 12, 'coal': 13, 'uranium': 14}[r_type], x, y] = amt / 800\n        elif input_identifier == 'rp':\n            # Research Points\n            team = int(strs[1])\n            rp = int(strs[2])\n            b[15 + (team - obs['player']) % 2, :] = min(rp, 200) / 200\n        elif input_identifier == 'c':\n            # Cities\n            city_id = strs[2]\n            fuel = float(strs[3])\n            lightupkeep = float(strs[4])\n            cities[city_id] = min(fuel / lightupkeep, 10) / 10\n    \n    # Day/Night Cycle\n    b[17, :] = obs['step'] % 40 / 40\n    # Turns\n    b[18, :] = obs['step'] / 360\n    # Map Size\n    b[19, x_shift:32 - x_shift, y_shift:32 - y_shift] = 1\n\n    return b\n\n\nclass LuxDataset(Dataset):\n    def __init__(self, obses, samples):\n        self.obses = obses\n        self.samples = samples\n        \n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        obs_id, unit_id, action = self.samples[idx]\n        obs = self.obses[obs_id]\n        state = make_input(obs, unit_id)\n        \n        return state, action","metadata":{"execution":{"iopub.status.busy":"2021-10-21T11:22:05.575370Z","iopub.execute_input":"2021-10-21T11:22:05.575936Z","iopub.status.idle":"2021-10-21T11:22:05.611846Z","shell.execute_reply.started":"2021-10-21T11:22:05.575900Z","shell.execute_reply":"2021-10-21T11:22:05.611133Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"class CBasicConv2d(nn.Module):\n    def __init__(self, input_dim, output_dim, kernel_size, bn):\n        super().__init__()\n        self.conv = nn.Conv2d(\n            input_dim, output_dim, \n            kernel_size=kernel_size, \n            padding=(kernel_size[0] // 2, kernel_size[1] // 2)\n        )\n        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n\n    def forward(self, x):\n        h = self.conv(x)\n        h = self.bn(h) if self.bn is not None else h\n        return h\n\nclass LuxNet(nn.Module):\n    def __init__( self, n_actions ):\n        super().__init__()\n        layers, filters = 12, 32\n        self.conv = CBasicConv2d(20, filters, (3, 3), True)\n        self.blocks = nn.ModuleList([\n            CBasicConv2d(filters, filters, (3, 3), True) for _ in range( layers )\n        ])\n        self.head = nn.Linear( filters, n_actions, bias=False )\n\n    def forward(self, x):\n        h = F.relu_( self.conv(x) )\n        for b in self.blocks:\n            h = F.relu_( h + b( h ) )\n        h = ( h * x[:, :1] ).view( h.size(0), h.size(1), -1 ).sum(-1)\n        ret = self.head( h )\n        return ret ","metadata":{"execution":{"iopub.status.busy":"2021-10-21T11:29:17.378218Z","iopub.execute_input":"2021-10-21T11:29:17.378523Z","iopub.status.idle":"2021-10-21T11:29:17.389314Z","shell.execute_reply.started":"2021-10-21T11:29:17.378488Z","shell.execute_reply":"2021-10-21T11:29:17.388601Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"EPS_START = 0.9\nEPS_END = 0.05\nEPS_DECAY = 200\nsteps_done = 0\ndef select_action(state, model):\n    global steps_done\n    sample = random.random()\n    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n        math.exp(-1. * steps_done / EPS_DECAY)\n    steps_done += 1\n    if sample > eps_threshold:\n        with torch.no_grad():\n            # t.max(1) will return largest column value of each row.\n            # second column on max result is index of where max element was\n            # found, so we pick action with the larger expected reward.\n            return model(state)\n    else:\n        return torch.tensor([[random.randrange(n_actions)]], device=device)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T11:29:17.548274Z","iopub.execute_input":"2021-10-21T11:29:17.548756Z","iopub.status.idle":"2021-10-21T11:29:17.554634Z","shell.execute_reply.started":"2021-10-21T11:29:17.548708Z","shell.execute_reply":"2021-10-21T11:29:17.553755Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"from collections import namedtuple\nTransition = namedtuple('Transition',\n                        ('state', 'action', 'next_state', 'reward'))\n\n\nclass ReplayMemory(object):\n\n    def __init__(self, capacity):\n        self.memory = deque([],maxlen=capacity)\n\n    def push(self, *args):\n        \"\"\"Save a transition\"\"\"\n        self.memory.append(Transition(*args))\n\n    def sample(self, batch_size):\n        return random.sample(self.memory, batch_size)\n\n    def __len__(self):\n        return len(self.memory)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T11:29:17.720048Z","iopub.execute_input":"2021-10-21T11:29:17.720453Z","iopub.status.idle":"2021-10-21T11:29:17.726867Z","shell.execute_reply.started":"2021-10-21T11:29:17.720422Z","shell.execute_reply":"2021-10-21T11:29:17.725851Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"def train_model(model, dataloaders_dict, criterion, optimizer, num_epochs):\n    global policy_net\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        model.cuda()\n        \n        for phase in ['train', 'val']:\n            if phase == 'train':\n                policy_net.train()\n            else:\n                model.eval()\n                \n            epoch_loss = 0.0\n            epoch_acc = 0\n            \n            dataloader = dataloaders_dict[phase]\n            for item in tqdm(dataloader, leave=False):\n                states = item[0].cuda().float()\n                actions = item[1].cuda().long()\n\n                optimizer.zero_grad()\n                \n                with torch.set_grad_enabled(phase == 'train'):\n                    policy = model(states)#select_action(states, model)\n                    loss = criterion(policy, actions)\n                    _, preds = torch.max(policy, 1)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                    epoch_loss += loss.item() * len(policy)\n                    epoch_acc += torch.sum(preds == actions.data)\n\n            data_size = len(dataloader.dataset)\n            epoch_loss = epoch_loss / data_size\n            epoch_acc = epoch_acc.double() / data_size\n\n            print(f'Epoch {epoch + 1}/{num_epochs} | {phase:^5} | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}')\n        \n        if epoch_acc > best_acc:\n            traced = torch.jit.trace(model.cpu(), torch.rand(1, 20, 32, 32))\n            traced.save('model.pth')\n            best_acc = epoch_acc\n            \n        model.load_state_dict(policy_net.state_dict())\n","metadata":{"execution":{"iopub.status.busy":"2021-10-21T11:29:17.943804Z","iopub.execute_input":"2021-10-21T11:29:17.944182Z","iopub.status.idle":"2021-10-21T11:29:17.954675Z","shell.execute_reply.started":"2021-10-21T11:29:17.944151Z","shell.execute_reply":"2021-10-21T11:29:17.953639Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"policy_net = LuxNet(n_actions)\ntarget_net = LuxNet(n_actions)\ntarget_net.load_state_dict(policy_net.state_dict())\ntarget_net.eval()\n\ntrain, val = train_test_split(samples, test_size=0.1, random_state=42, stratify=labels)\nbatch_size = 32\ntrain_loader = DataLoader(\n    LuxDataset(obses, train), \n    batch_size=batch_size, \n    shuffle=True, \n    num_workers=2\n)\nval_loader = DataLoader(\n    LuxDataset(obses, val), \n    batch_size=batch_size, \n    shuffle=False, \n    num_workers=2\n)\ndataloaders_dict = {\"train\": train_loader, \"val\": val_loader}\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(target_net.parameters(), lr=1e-3)\n# optimizer = torch.optim.RMSprop(target_net.parameters(), lr=1e-3)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T11:29:18.563648Z","iopub.execute_input":"2021-10-21T11:29:18.564334Z","iopub.status.idle":"2021-10-21T11:29:18.731155Z","shell.execute_reply.started":"2021-10-21T11:29:18.564297Z","shell.execute_reply":"2021-10-21T11:29:18.730402Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"train_model(target_net, dataloaders_dict, criterion, optimizer, num_epochs=15)","metadata":{"execution":{"iopub.status.busy":"2021-10-21T11:29:18.904560Z","iopub.execute_input":"2021-10-21T11:29:18.904810Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"%%writefile agent.py\nimport os\nimport numpy as np\nimport torch\nfrom lux.game import Game\n\n\npath = '/kaggle_simulations/agent' if os.path.exists('/kaggle_simulations') else '.'\nmodel = torch.jit.load(f'{path}/model.pth')\nmodel.eval()\n\n\ndef make_input(obs, unit_id):\n    width, height = obs['width'], obs['height']\n    x_shift = (32 - width) // 2\n    y_shift = (32 - height) // 2\n    cities = {}\n    \n    b = np.zeros((20, 32, 32), dtype=np.float32)\n    \n    for update in obs['updates']:\n        strs = update.split(' ')\n        input_identifier = strs[0]\n        \n        if input_identifier == 'u':\n            x = int(strs[4]) + x_shift\n            y = int(strs[5]) + y_shift\n            wood = int(strs[7])\n            coal = int(strs[8])\n            uranium = int(strs[9])\n            if unit_id == strs[3]:\n                # Position and Cargo\n                b[:2, x, y] = (\n                    1,\n                    (wood + coal + uranium) / 100\n                )\n            else:\n                # Units\n                team = int(strs[2])\n                cooldown = float(strs[6])\n                idx = 2 + (team - obs['player']) % 2 * 3\n                b[idx:idx + 3, x, y] = (\n                    1,\n                    cooldown / 6,\n                    (wood + coal + uranium) / 100\n                )\n        elif input_identifier == 'ct':\n            # CityTiles\n            team = int(strs[1])\n            city_id = strs[2]\n            x = int(strs[3]) + x_shift\n            y = int(strs[4]) + y_shift\n            idx = 8 + (team - obs['player']) % 2 * 2\n            b[idx:idx + 2, x, y] = (\n                1,\n                cities[city_id]\n            )\n        elif input_identifier == 'r':\n            # Resources\n            r_type = strs[1]\n            x = int(strs[2]) + x_shift\n            y = int(strs[3]) + y_shift\n            amt = int(float(strs[4]))\n            b[{'wood': 12, 'coal': 13, 'uranium': 14}[r_type], x, y] = amt / 800\n        elif input_identifier == 'rp':\n            # Research Points\n            team = int(strs[1])\n            rp = int(strs[2])\n            b[15 + (team - obs['player']) % 2, :] = min(rp, 200) / 200\n        elif input_identifier == 'c':\n            # Cities\n            city_id = strs[2]\n            fuel = float(strs[3])\n            lightupkeep = float(strs[4])\n            cities[city_id] = min(fuel / lightupkeep, 10) / 10\n    \n    # Day/Night Cycle\n    b[17, :] = obs['step'] % 40 / 40\n    # Turns\n    b[18, :] = obs['step'] / 360\n    # Map Size\n    b[19, x_shift:32 - x_shift, y_shift:32 - y_shift] = 1\n\n    return b\n\n\ngame_state = None\ndef get_game_state(observation):\n    global game_state\n    \n    if observation[\"step\"] == 0:\n        game_state = Game()\n        game_state._initialize(observation[\"updates\"])\n        game_state._update(observation[\"updates\"][2:])\n        game_state.id = observation[\"player\"]\n    else:\n        game_state._update(observation[\"updates\"])\n    return game_state\n\n\ndef in_city(pos):    \n    try:\n        city = game_state.map.get_cell_by_pos(pos).citytile\n        return city is not None and city.team == game_state.id\n    except:\n        return False\n\n\ndef call_func(obj, method, args=[]):\n    return getattr(obj, method)(*args)\n\n\nunit_actions = [('move', 'n'), ('move', 's'), ('move', 'w'), ('move', 'e'), ('build_city',)]\ndef get_action(policy, unit, dest):\n    for label in np.argsort(policy)[::-1]:\n        act = unit_actions[label]\n        pos = unit.pos.translate(act[-1], 1) or unit.pos\n        if pos not in dest or in_city(pos):\n            return call_func(unit, *act), pos \n            \n    return unit.move('c'), unit.pos\n\n\ndef agent(observation, configuration):\n    global game_state\n    \n    game_state = get_game_state(observation)    \n    player = game_state.players[observation.player]\n    actions = []\n    \n    # City Actions\n    unit_count = len(player.units)\n    for city in player.cities.values():\n        for city_tile in city.citytiles:\n            if city_tile.can_act():\n                if unit_count < player.city_tile_count: \n                    actions.append(city_tile.build_worker())\n                    unit_count += 1\n                elif not player.researched_uranium():\n                    actions.append(city_tile.research())\n                    player.research_points += 1\n    \n    # Worker Actions\n    dest = []\n    for unit in player.units:\n        if unit.can_act() and (game_state.turn % 40 < 30 or not in_city(unit.pos)):\n            state = make_input(observation, unit.id)\n            with torch.no_grad():\n                p = model(torch.from_numpy(state).unsqueeze(0))\n\n            policy = p.squeeze(0).numpy()\n\n            action, pos = get_action(policy, unit, dest)\n            actions.append(action)\n            dest.append(pos)\n\n    return actions","metadata":{"execution":{"iopub.status.busy":"2021-09-21T02:12:28.574817Z","iopub.status.idle":"2021-09-21T02:12:28.575768Z","shell.execute_reply.started":"2021-09-21T02:12:28.575505Z","shell.execute_reply":"2021-09-21T02:12:28.575542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_environments import make\n\nenv = make(\"lux_ai_2021\", configuration={\"width\": 24, \"height\": 24, \"loglevel\": 2, \"annotations\": True}, debug=False)\nsteps = env.run(['agent.py', 'agent.py'])\nenv.render(mode=\"ipython\", width=1200, height=800)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T02:12:28.577249Z","iopub.status.idle":"2021-09-21T02:12:28.577694Z","shell.execute_reply.started":"2021-09-21T02:12:28.577455Z","shell.execute_reply":"2021-09-21T02:12:28.577478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!tar -czf submission.tar.gz *","metadata":{"execution":{"iopub.status.busy":"2021-09-21T02:12:28.579045Z","iopub.status.idle":"2021-09-21T02:12:28.579564Z","shell.execute_reply.started":"2021-09-21T02:12:28.579334Z","shell.execute_reply":"2021-09-21T02:12:28.579355Z"},"trusted":true},"execution_count":null,"outputs":[]}]}